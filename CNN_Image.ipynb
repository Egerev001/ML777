{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Классификация изображений с помощью свёрточной нейронной сети (CNN)"
      ],
      "metadata": {
        "id": "pAYvd3DArAxm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Импортируем необходимые библиотеки"
      ],
      "metadata": {
        "id": "OWZCYwocrp86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "_EyfvMVtrqeJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogOwF-p1cuvE",
        "outputId": "fb40bd4c-e8bb-487b-e168-9c9ca479d547"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Распакуем данные"
      ],
      "metadata": {
        "id": "zw27Zw5NrcNF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "if6Kx86Dq6k_"
      },
      "outputs": [],
      "source": [
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Функция load_data(batch) - метод для передора вскх пакетов в cifar-10, из разбора и загрузки в массивы X и Y.\n",
        "\n",
        "X - массив, содержащий вск данные изображения из загруженных пакетов.\n",
        "\n",
        "Y - массив соответствующих меток для всех изображений в X.\n",
        "\n"
      ],
      "metadata": {
        "id": "1lSK4OiEsH36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(batch):\n",
        "    data = unpickle('/content/gdrive/MyDrive/cifar/' + batch)\n",
        "    X = data[b'data']\n",
        "    Y = data[b'labels']\n",
        "    for i in range(2,6):\n",
        "        data = unpickle('/content/gdrive/MyDrive/cifar/data_batch_'+str(i))\n",
        "        X = np.concatenate((X,data[b'data']))\n",
        "        Y = np.concatenate((Y,data[b'labels']))\n",
        "    return X,Y"
      ],
      "metadata": {
        "id": "GNXavj-YrmuP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Имрортируем torch и подготовим данные"
      ],
      "metadata": {
        "id": "iLIuT8DAtgfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Импортируем необходимые библиотеки PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n"
      ],
      "metadata": {
        "id": "s5CZRn1Ht6YX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подготовим данные"
      ],
      "metadata": {
        "id": "3aMtEJuUuZfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X,Y = load_data('data_batch_1')\n",
        "\n",
        "# Изменение формы данных: изображения CIFAR-10 имеют размер 32x32 пикселей с 3 каналами (RGB).\n",
        "# -1 в reshape означает автоматическое вычисление размера этого измерения\n",
        "X = X.reshape(-1, 3, 32, 32) / 255.0\n",
        "\n",
        "# Преобразование меток в тензор PyTorch типа long (который используется для целочисленных меток)\n",
        "Y = torch.tensor(Y).long()\n",
        "\n",
        "# Преобразование объектов в тензор PyTorch с типом float32\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "\n",
        "# Создание TensorDataset, который представляет собой набор данных, обертывающий тензоры\n",
        "dataset = TensorDataset(X, Y)\n",
        "\n",
        "# DataLoader для перебора набора данных с указанным размером пакета\n",
        "# shuffle=True для перемешивания набора данных каждую эпоху\n",
        "train_loader = DataLoader(dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "vI9s82_P2zK2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Определим CNN"
      ],
      "metadata": {
        "id": "RIO4p1Os49Q7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Определить класс CNN, наследующий от nn.Module\n",
        "class SimpleCNN(nn.Module):\n",
        "    # Конструктор для определения слоев\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        # Первый сверточный слой с 32 фильтрами размера 3x3 , шаг 1 и заполнение 1\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # Максимальный слой пула с окном 2x2 и шагом 2\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        # Второй сверточный слой с 64 фильтрами размера 3x3, шаг 1 и заполнение 1\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # Полносвязный слой, 64 * 8 * 8 — это сглаженный размер свернутых изображений\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
        "\n",
        "        # Второй полносвязный слой, который выводит 10 классов (для CIFAR-10 )\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    # Затем для CNN определяется прямой метод, который определяет, как данные изображения перемещаются по слоям для создания прогнозов классов\n",
        "    # Прямой проход через сеть\n",
        "    def forward(self, x):\n",
        "        # Применяем первую свертку, за которой следует активация ReLU и объединение в пул\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "\n",
        "        # Применяем вторую свертку, а затем Активация и объединение ReLU\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "\n",
        "        # Сглаживаем тензор для полностью связного слоя\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "\n",
        "        # Применяем первый полносвязный слой с активацией ReLU\n",
        "        x = F.relu(self.fc1(x))\n",
        "\n",
        "         # Применяем второй полносвязный слой\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        # Возвращаем выходные данные\n",
        "        return x"
      ],
      "metadata": {
        "id": "J-nbeLO744eT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь определим цикл, который мы будем использовать для обучения нашей модели."
      ],
      "metadata": {
        "id": "AbcwM0Bm8hMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU availability and set the device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Создание экземпляра модели CNN и перенос его на выбранное устройство (GPU или CPU)\n",
        "model = SimpleCNN().to(device)\n",
        "\n",
        "# Определение функции потерь (для классификации используется CrossEntropyLoss)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Определение оптимизатора (стохастический градиентный спуск) со скоростью обучения и импульсом\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Цикл обучения\n",
        "for epoch in range(15):\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # Обнуляем градиенты\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Переход вперед: вычисляем прогнозируемые выходные данные\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Вычисляем потери\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Perform backpropagation: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Perform optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "\n",
        "    # Print loss after each epoch\n",
        "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
        "\n",
        "# Print a message when training is finished\n",
        "print(\"Finished Training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyWexNu777eP",
        "outputId": "78a43692-2cee-49d4-e743-1bac49e8bb68"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.029019594192505\n",
            "Epoch 2, Loss: 1.918224573135376\n",
            "Epoch 3, Loss: 1.7451707124710083\n",
            "Epoch 4, Loss: 1.6826088428497314\n",
            "Epoch 5, Loss: 1.8255927562713623\n",
            "Epoch 6, Loss: 0.9288021922111511\n",
            "Epoch 7, Loss: 1.4745497703552246\n",
            "Epoch 8, Loss: 1.14347243309021\n",
            "Epoch 9, Loss: 1.0831741094589233\n",
            "Epoch 10, Loss: 1.1212232112884521\n",
            "Epoch 11, Loss: 1.061507225036621\n",
            "Epoch 12, Loss: 0.8533371090888977\n",
            "Epoch 13, Loss: 1.0768177509307861\n",
            "Epoch 14, Loss: 1.5244405269622803\n",
            "Epoch 15, Loss: 0.9759458899497986\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сохраняем обученную модель"
      ],
      "metadata": {
        "id": "-EXRrpPmA_0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Сохраняем всю модель\n",
        "# torch.save(model, 'cifar10_model_full.pth')\n",
        "\n",
        "# Сохраняем только словарь состояний\n",
        "torch.save(model.state_dict(), 'cifar10_model_state_dict.pth')\n",
        "\n",
        "# Сохраним на гугл диск\n",
        "! touch \"/content/gdrive/MyDrive/cifar/cifar10_model_state_dict.pth\""
      ],
      "metadata": {
        "id": "sqpB-x1JBFuV"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model (must be the same architecture as the trained model)\n",
        "model = SimpleCNN()\n",
        "\n",
        "# Load the state dictionary into the model (assuming state dictionary was saved)\n",
        "model.load_state_dict(torch.load('cifar10_model_state_dict.pth'))\n",
        "# Set the model to evaluation mode\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OL9R7I2UBUKo",
        "outputId": "3259f129-1907-401a-eb2f-c25e5863bb8f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleCNN(\n",
              "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (fc1): Linear(in_features=4096, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тестовые данные"
      ],
      "metadata": {
        "id": "dcUjxgvGBgwo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WFjMiCWtdUKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unpickle the test data\n",
        "test_data = unpickle('/content/gdrive/MyDrive/cifar/test_batch')"
      ],
      "metadata": {
        "id": "Sh7ksx0qBiO4"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подсчитаем точность модели на тестовом наборе данных"
      ],
      "metadata": {
        "id": "zbHTxYXwBxhv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Извлекаем объекты (X_test) и метки (Y_test) из тестовых данных\n",
        "X_test = test_data[b'data']\n",
        "Y_test = test_data[b'labels']\n",
        "\n",
        "# Изменяем форму и нормализовываем тестовые данные\n",
        "# Тестовые изображения CIFAR-10 имеют размер 32x32 пикселя с 3 цветовых канала (RGB)\n",
        "X_test = X_test.reshape(-1, 3, 32, 32) / 255.0\n",
        "\n",
        "# Преобразование тестовых данных в тензоры PyTorch\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "Y_test = torch.tensor(Y_test).long()\n",
        "\n",
        "# Создание DataLoader для тестовых данных\n",
        "test_dataset = TensorDataset(X_test, Y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# Загружаем обученную модель (при условии, что state dictionary сохранен)\n",
        "model = SimpleCNN()\n",
        "model.load_state_dict(torch.load('cifar10_model_state_dict.pth'))\n",
        "model.eval()\n",
        "\n",
        "# Оценка модели на тестовых данных\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the test images: {100 * correct / total}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71-75PyeB2fe",
        "outputId": "adbca80f-5ba6-43d2-a4b4-86180438e750"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 61.82%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Определим методы загрузки и обработки, которые могут использовать мой тип модели для классификации моих изображений"
      ],
      "metadata": {
        "id": "Lhv3QOxJEFt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Функция для загрузки и предварительной обработки изображения\n",
        "def process_image(image_path):\n",
        "    # Преобразования изображений\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((32, 32)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # CIFAR-10 normalization\n",
        "    ])\n",
        "\n",
        "   # Загрузка изображения\n",
        "    image = Image.open(image_path)\n",
        "    image = image.convert('RGB')  # Convert to RGB\n",
        "\n",
        "    # Примененение преобразования\n",
        "    return transform(image)\n",
        "\n",
        "# Функция для классификации изображения\n",
        "def classify_image(image_path, model_path):\n",
        "    # Загружаем и обрабатываем изображение\n",
        "    image = process_image(image_path)\n",
        "\n",
        "    # Добавляем дополнительное измерение пакета, поскольку PyTorch рассматривает все входные данные как пакеты\n",
        "    image = image.unsqueeze(0)\n",
        "\n",
        "    # Загружаем обученную модель\n",
        "    model = SimpleCNN()\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    # Классифицируем изображение\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    # Преобразование прогнозируемого индекса класса в имя класса (если имена классов доступны)\n",
        "    # Для CIFAR-10 классы:\n",
        "    classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "    predicted_class = classes[predicted[0]]\n",
        "\n",
        "    return predicted_class"
      ],
      "metadata": {
        "id": "SdkqPoy0DEpc"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Определяем свои собственные изображения"
      ],
      "metadata": {
        "id": "oKPl6M1nERFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = '/content/gdrive/MyDrive/cifar/MC21.jpg'\n",
        "model_path = 'cifar10_model_state_dict.pth'\n",
        "predicted_class = classify_image(image_path, model_path)\n",
        "print(f'Predicted class: {predicted_class}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMaoTr3TEXHL",
        "outputId": "92e798f3-8d77-41e6-d077-d1c7a1d52678"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: airplane\n"
          ]
        }
      ]
    }
  ]
}